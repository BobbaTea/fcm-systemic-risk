{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math, pdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit, njit, vectorize, float64, cuda\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize([float64(float64)])\n",
    "def activation(x):\n",
    "    return 1 / (1 + math.exp(-1*x))\n",
    "\n",
    "@vectorize([float64(float64)])\n",
    "def dactivation(x):\n",
    "    return activation(x)*(1-activation(x))\n",
    "\n",
    "@njit\n",
    "def simulate(weights, concepts, noactivation = False):\n",
    "    res = np.empty((0))\n",
    "    for i, concept in enumerate(concepts):\n",
    "        vweights = weights[:,i]\n",
    "        vweights = vweights[~np.isnan(vweights)]\n",
    "        vconcepts = np.delete(concepts, i)\n",
    "        vweights = np.ascontiguousarray(vweights)\n",
    "        vconcepts = np.ascontiguousarray(vconcepts)\n",
    "        pot = np.dot(vweights, vconcepts)\n",
    "        if noactivation:\n",
    "            res = np.append(res, pot)\n",
    "        else:\n",
    "            res = np.append(res, activation(pot))\n",
    "    return res\n",
    "\n",
    "@njit\n",
    "def activate(arr):\n",
    "    for a in range(len(arr)):\n",
    "        arr[a] = activation(arr[a])\n",
    "    return arr\n",
    "\n",
    "@njit\n",
    "def deltaRule(data, weights, lc):\n",
    "    for i in range(1, data.shape[0]):\n",
    "        lr = lc\n",
    "        pots = simulate(weights, data[i-1], True)\n",
    "        error = data[i] - activate(pots)\n",
    "        for a in range(len(weights)):\n",
    "            weightarr = weights[a]\n",
    "            for b in range(len(weightarr)):\n",
    "                weight = weightarr[b]\n",
    "                if not np.isnan(weight):\n",
    "                    weights[a][b] += lr * (error[b] * dactivation(pots[b])) * data[i-1][a]\n",
    "    return weights\n",
    "\n",
    "@njit\n",
    "def generateData(SAMPLES,  ref_weights):\n",
    "    trainingData = np.empty((0,SIZE))\n",
    "#     trainingData = []\n",
    "    for i in range(SAMPLES):\n",
    "#         trainingData.append(np.random.uniform(0,1, SIZE))\n",
    "#         trainingData.append(simulate(ref_weights, trainingData[-1]))\n",
    "        trainingData = np.append(trainingData, np.random.uniform(0,1, SIZE).reshape(1,SIZE), axis=0)\n",
    "        trainingData = np.append(trainingData, simulate(ref_weights, trainingData[-1]).reshape(1,SIZE), axis=0)\n",
    "    return trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28526305 0.44706645 0.68808789 0.62838708 0.31311637 0.11422091]\n",
      " [0.91968647 0.30670925 0.71724532 0.76653272 0.81489021 0.07717606]\n",
      " [0.74901045 0.7311007  0.14442611 0.78463502 0.45523177 0.84492156]\n",
      " ...\n",
      " [0.91655549 0.20802314 0.77780933 0.68781398 0.8794489  0.06243012]\n",
      " [0.61413726 0.89234066 0.57502176 0.06568526 0.10171798 0.3849875 ]\n",
      " [0.9430179  0.3275158  0.57941453 0.83638104 0.40999601 0.17323618]]\n",
      "Generation completed in 7448.61 ms\n",
      "Training completed in 407.95 ms\n",
      "\n",
      "[[ nan -0.5 -1.2  0.2 -0.2 -0.9]\n",
      " [ 2.   nan  1.4  1.1 -0.9  0.1]\n",
      " [ 1.1  0.6  nan  1.7  1.9 -1.7]\n",
      " [ 1.8 -1.6  1.9  nan  1.3 -1.7]\n",
      " [-1.5  0.4 -1.6 -1.4  nan -0.1]\n",
      " [ 1.1 -1.8 -0.4 -0.8 -1.6  nan]]\n",
      "\n",
      "[[        nan  0.52097877 -0.60876893 -0.21796912 -1.02456315  1.1929919 ]\n",
      " [ 1.98691407         nan  0.97542075  1.24003913 -0.3063502  -2.11080933]\n",
      " [ 0.40405132  0.37800193         nan  1.25381089  1.21679784 -1.28169763]\n",
      " [ 0.12699317 -1.04471238  1.67755604         nan  0.74439194 -0.60548126]\n",
      " [-1.18474213  0.33787598 -1.20281029 -1.17397689         nan  0.14709956]\n",
      " [ 1.97430277 -2.43599921 -0.70806026 -0.57940745 -0.67175681         nan]]\n"
     ]
    }
   ],
   "source": [
    "SAMPLES = 20000\n",
    "# SIZE = len(stocks)\n",
    "SIZE = 6\n",
    "LEARNING_COEFFICIENT = 0.2\n",
    "MIN_WEIGHT = -2\n",
    "MAX_WEIGHT = 2\n",
    "np.random.seed(2)\n",
    "\n",
    "ref_concepts = np.zeros(SIZE)\n",
    "ref_weights = (np.random.randint(MIN_WEIGHT*10, (MAX_WEIGHT*10)+1, SIZE**2)/10).reshape(SIZE,SIZE)\n",
    "np.fill_diagonal(ref_weights, np.nan)\n",
    "\n",
    "res_concepts = np.zeros(SIZE)\n",
    "res_weights = (np.zeros(SIZE**2)).reshape(SIZE,SIZE)\n",
    "np.fill_diagonal(res_weights, np.nan)\n",
    "\n",
    "start = time.time()\n",
    "trainingData = generateData(SAMPLES, ref_weights)\n",
    "print(trainingData)\n",
    "# trainingData = np.array(list(zip(*list(res.values()))))\n",
    "end = time.time()\n",
    "print(f\"Generation completed in {round((end-start)*1000,2)} ms\")\n",
    "\n",
    "start = time.time()\n",
    "deltaRule(trainingData, res_weights, LEARNING_COEFFICIENT)\n",
    "end = time.time()\n",
    "print(f\"Training completed in {round((end-start)*1000,2)} ms\")\n",
    "\n",
    "print()\n",
    "print(ref_weights)\n",
    "print()\n",
    "print(res_weights)\n",
    "# print(\"\\t\", end= \"\")\n",
    "# for item in stocks:\n",
    "#     print(item + \"↑\\t\", end=\"\")\n",
    "# print()\n",
    "# processed = []\n",
    "# for a, row in enumerate(res_weights):\n",
    "#     tmp = []\n",
    "#     for b, item in enumerate(row):\n",
    "#         tmp.append(res_weights[a][b]/res_weights[b][a])\n",
    "#     processed.append(tmp)\n",
    "# cmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\n",
    "# sns.heatmap(processed, annot=True, cmap=cmap)\n",
    "# for i, row in enumerate(res_weights):\n",
    "#     print(stocks[i] + \"→\\t\", end = \"\")\n",
    "#     for item in row:\n",
    "#         print(str(round(item,2)) + \"\\t\", end=\"\")\n",
    "#     print()\n",
    "# print()\n",
    "# print(\"\\t\", end= \"\")\n",
    "# for item in stocks:\n",
    "#     print(item + \"↑\\t\", end=\"\")\n",
    "# print()\n",
    "    \n",
    "# for i, row in enumerate(processed):\n",
    "#     print(stocks[i] + \"→\\t\", end = \"\")\n",
    "#     for item in row:\n",
    "#         print(str(round(item,2)) + \"\\t\", end=\"\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "stocks = [\"GOOG\", \"GOOGL\", \"BRK-A\", \"BRK-B\", \"AAL\", \"DAL\", \"GLU\", \"RYAAY\"]\n",
    "data = yf.download(stocks, start=\"2011-03-01\", end=\"2020-08-21\", interval=\"1d\", group_by=\"ticker\", threads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for stock in stocks:\n",
    "    start = data[stock]['High'].iloc[0]\n",
    "    res[stock] = []\n",
    "    for end in data[stock]['High']:\n",
    "        res[stock].append((end-start)/start)\n",
    "    res[stock] = res[stock]*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
